{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Bike Rentals\n",
    "\n",
    "Many American cities have communal bike sharing stations where you can rent bicycles by the hour or day. Washington D.C. is one of those cities. The District collects detailed data on the number of bicycles people rent by the hour and day.\n",
    "\n",
    "The dataset we will be working with was compiled by Hadi Fanaee-T at the University of Porto. You can download the data from the [University of California, Irvine's website](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset). \n",
    "\n",
    "In this project, we will try to predict the total number of bikes people rented in a given hour. In the dataset, the value we are predicting is the 'cnt' column and we will use all columns except for 'casual' and 'registered'. To accomplish this, we will create a few different machine learning models and evaluate their performance.\n",
    "\n",
    "Let's start by investigating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "bike_rentals = pd.read_csv('bike_rental_hour.csv')\n",
    "bike_rentals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17379 entries, 0 to 17378\n",
      "Data columns (total 17 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   instant     17379 non-null  int64  \n",
      " 1   dteday      17379 non-null  object \n",
      " 2   season      17379 non-null  int64  \n",
      " 3   yr          17379 non-null  int64  \n",
      " 4   mnth        17379 non-null  int64  \n",
      " 5   hr          17379 non-null  int64  \n",
      " 6   holiday     17379 non-null  int64  \n",
      " 7   weekday     17379 non-null  int64  \n",
      " 8   workingday  17379 non-null  int64  \n",
      " 9   weathersit  17379 non-null  int64  \n",
      " 10  temp        17379 non-null  float64\n",
      " 11  atemp       17379 non-null  float64\n",
      " 12  hum         17379 non-null  float64\n",
      " 13  windspeed   17379 non-null  float64\n",
      " 14  casual      17379 non-null  int64  \n",
      " 15  registered  17379 non-null  int64  \n",
      " 16  cnt         17379 non-null  int64  \n",
      "dtypes: float64(4), int64(12), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "bike_rentals.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values, but we will need to convert some columns to the right data type, such as dteday. Before we start cleaning the data, lets examine the distribution of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6972., 3705., 2659., 1660.,  987.,  663.,  369.,  188.,  139.,\n",
       "          37.]),\n",
       " array([  1. ,  98.6, 196.2, 293.8, 391.4, 489. , 586.6, 684.2, 781.8,\n",
       "        879.4, 977. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(bike_rentals['cnt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most hours have between 0-200 rentals per hour. The distribution is heavily right-skewed. Next, lets examine how each column correlates with cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cnt           1.000000\n",
       "registered    0.972151\n",
       "casual        0.694564\n",
       "temp          0.404772\n",
       "atemp         0.400929\n",
       "hr            0.394071\n",
       "hum           0.322911\n",
       "instant       0.278379\n",
       "yr            0.250495\n",
       "season        0.178056\n",
       "weathersit    0.142426\n",
       "mnth          0.120638\n",
       "windspeed     0.093234\n",
       "holiday       0.030927\n",
       "workingday    0.030284\n",
       "weekday       0.026900\n",
       "Name: cnt, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(bike_rentals.corr()['cnt']).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature, time of day, and humidity are most strongly correlated with number of rides per hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "It can be helpful to calculate new features to introduce new information or to distill existing information.\n",
    "\n",
    "The hr column contains the hours during which bikes were rented, from 1 to 24. A machine will treat each hour differently, without understanding that some hours are related. Lets create labels for the time of day (morning, afternoon, evening, night) to bundle similar times together, allowing the model to make better decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "      <th>time_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>17375</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>11</td>\n",
       "      <td>108</td>\n",
       "      <td>119</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>17376</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>8</td>\n",
       "      <td>81</td>\n",
       "      <td>89</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17376</th>\n",
       "      <td>17377</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>7</td>\n",
       "      <td>83</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17377</th>\n",
       "      <td>17378</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17378</th>\n",
       "      <td>17379</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17379 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       instant      dteday  season  yr  mnth  hr  holiday  weekday  \\\n",
       "0            1  2011-01-01       1   0     1   0        0        6   \n",
       "1            2  2011-01-01       1   0     1   1        0        6   \n",
       "2            3  2011-01-01       1   0     1   2        0        6   \n",
       "3            4  2011-01-01       1   0     1   3        0        6   \n",
       "4            5  2011-01-01       1   0     1   4        0        6   \n",
       "...        ...         ...     ...  ..   ...  ..      ...      ...   \n",
       "17374    17375  2012-12-31       1   1    12  19        0        1   \n",
       "17375    17376  2012-12-31       1   1    12  20        0        1   \n",
       "17376    17377  2012-12-31       1   1    12  21        0        1   \n",
       "17377    17378  2012-12-31       1   1    12  22        0        1   \n",
       "17378    17379  2012-12-31       1   1    12  23        0        1   \n",
       "\n",
       "       workingday  weathersit  temp   atemp   hum  windspeed  casual  \\\n",
       "0               0           1  0.24  0.2879  0.81     0.0000       3   \n",
       "1               0           1  0.22  0.2727  0.80     0.0000       8   \n",
       "2               0           1  0.22  0.2727  0.80     0.0000       5   \n",
       "3               0           1  0.24  0.2879  0.75     0.0000       3   \n",
       "4               0           1  0.24  0.2879  0.75     0.0000       0   \n",
       "...           ...         ...   ...     ...   ...        ...     ...   \n",
       "17374           1           2  0.26  0.2576  0.60     0.1642      11   \n",
       "17375           1           2  0.26  0.2576  0.60     0.1642       8   \n",
       "17376           1           1  0.26  0.2576  0.60     0.1642       7   \n",
       "17377           1           1  0.26  0.2727  0.56     0.1343      13   \n",
       "17378           1           1  0.26  0.2727  0.65     0.1343      12   \n",
       "\n",
       "       registered  cnt  time_label  \n",
       "0              13   16           4  \n",
       "1              32   40           4  \n",
       "2              27   32           4  \n",
       "3              10   13           4  \n",
       "4               1    1           4  \n",
       "...           ...  ...         ...  \n",
       "17374         108  119           3  \n",
       "17375          81   89           3  \n",
       "17376          83   90           3  \n",
       "17377          48   61           3  \n",
       "17378          37   49           3  \n",
       "\n",
       "[17379 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def assign_label(hour):\n",
    "    if hour < 6:\n",
    "        return 4\n",
    "    elif hour < 12:\n",
    "        return 1\n",
    "    elif hour < 18:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "bike_rentals['time_label'] = bike_rentals['hr'].apply(assign_label)\n",
    "\n",
    "bike_rentals\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Train and Test Data\n",
    "\n",
    "We will need to split the data into a training dataset that we will train our algorithm with and a test dataset to evaluate our model. We will select 80% of our dataset for our training dataset and the rest for testing.\n",
    "\n",
    "The mean squared error metric makes the most sense to evaluate our model error. MSE works on continuous numeric data, which fits our data quite well since we are looking to predict the number of bikes rented in an hour, and not a categorical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = bike_rentals.sample(frac = .8)\n",
    "test = bike_rentals.loc[~bike_rentals.index.isin(train.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our train and test data, we are ready to apply machine learning models on our data.\n",
    "\n",
    "## Linear Regression Model\n",
    "\n",
    "Linear regression will likely work fairly well on the data, given that many of the columns are highly correlated with cnt.\n",
    "We will need to ignore the casual and registered columns because cnt is derived from them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  17251.40179481665 \n",
      "RMSE:  131.3445917988885\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "features = ['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday',\n",
    "            'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed',\n",
    "            'time_label']\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(train[features],train['cnt'])\n",
    "lr_predictions = lr.predict(test[features])\n",
    "\n",
    "lr_mse = mean_squared_error(test['cnt'],lr_predictions)\n",
    "lr_rmse = lr_mse**0.5\n",
    "print(\"MSE: \",lr_mse,'\\nRMSE: ',lr_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean squared error is very high. This is likely because our data has few extremely high rental counts, but mainly low counts. Large errors are penalized more with MSE, lreading to higher total error. \n",
    "\n",
    "Linear Regression is fairly resistant to overfitting the data because it is straightforward. It can also be prone to underfitting the data and not building a powerful enough model however. This means linear regression usually isnt the most accurate option.\n",
    "\n",
    "## Decision Tree Algorithm\n",
    "\n",
    "Let's now run a decision tree algorithm on our dataset and compare its error with linear regression.\n",
    "\n",
    "Decision trees tend to predict outcomes much more reliably than linear regression models. But because it is a fairly complex mode, it tends to overfit the dataset, expecially when we don't tweak parameters like maximum depth and minimum number of samples per leaf. Let's keep this in mind when building our decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE:  17251.40179481665 \n",
      "Decision Tree MSE:  3601.053006329114\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "tree.fit(train[features],train['cnt'])\n",
    "tree_predictions = tree.predict(test[features])\n",
    "tree_mse = mean_squared_error(test['cnt'],tree_predictions)\n",
    "\n",
    "print(\"Linear Regression MSE: \",lr_mse,'\\nDecision Tree MSE: ',tree_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree model significantly reduced our mean squared error! Let's continue to tweak some parameters of the DecisionTreeRegressor class to see if it improves our error value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE:  17251.40179481665 \n",
      "Simple Decision Tree MSE:  3601.053006329114 \n",
      "Decision Tree (min_samples_leaf = 5):  2767.3647852621157\n"
     ]
    }
   ],
   "source": [
    "tree1 = DecisionTreeRegressor(min_samples_leaf = 5)\n",
    "\n",
    "tree1.fit(train[features],train['cnt'])\n",
    "tree1_predictions = tree1.predict(test[features])\n",
    "tree1_mse = mean_squared_error(test['cnt'],tree1_predictions)\n",
    "\n",
    "print(\"Linear Regression MSE: \",lr_mse,\n",
    "      '\\nSimple Decision Tree MSE: ',\n",
    "      tree_mse,'\\nDecision Tree (min_samples_leaf = 5): ',tree1_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE:  17251.40179481665 \n",
      "Simple Decision Tree MSE:  3601.053006329114 \n",
      "Decision Tree (min_samples_leaf = 5):  2767.3647852621157 \n",
      "Decision Tree (min_samples_leaf = 10):  2785.745026001085\n"
     ]
    }
   ],
   "source": [
    "tree2 = DecisionTreeRegressor(min_samples_leaf = 10)\n",
    "\n",
    "tree2.fit(train[features],train['cnt'])\n",
    "tree2_predictions = tree2.predict(test[features])\n",
    "tree2_mse = mean_squared_error(test['cnt'],tree2_predictions)\n",
    "\n",
    "print(\"Linear Regression MSE: \",lr_mse,\n",
    "      '\\nSimple Decision Tree MSE: ',tree_mse,\n",
    "      '\\nDecision Tree (min_samples_leaf = 5): ',tree1_mse,\n",
    "      '\\nDecision Tree (min_samples_leaf = 10): ',tree2_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requiring 5 samples to be at a leaf node further improved results drastically. However, when we increased this value to 10, our error got worse. Let's stick to a value of 5 for this parameter. \n",
    "\n",
    "Let's experiment with the max_depth parameter as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE:  17251.40179481665 \n",
      "Simple Decision Tree MSE:  3601.053006329114 \n",
      "Decision Tree (min_samples_leaf = 5):  2767.3647852621157 \n",
      "Decision Tree (min_samples_leaf = 10):  2785.745026001085 \n",
      "Decision Tree (min_samples_leaf = 5,max_depth = 8):  5470.743332188596\n"
     ]
    }
   ],
   "source": [
    "tree3 = DecisionTreeRegressor(min_samples_leaf = 5,max_depth = 8)\n",
    "\n",
    "tree3.fit(train[features],train['cnt'])\n",
    "tree3_predictions = tree3.predict(test[features])\n",
    "tree3_mse = mean_squared_error(test['cnt'],tree3_predictions)\n",
    "\n",
    "print(\"Linear Regression MSE: \",lr_mse,\n",
    "      '\\nSimple Decision Tree MSE: ',tree_mse,\n",
    "      '\\nDecision Tree (min_samples_leaf = 5): ',tree1_mse,\n",
    "      '\\nDecision Tree (min_samples_leaf = 10): ',tree2_mse,\n",
    "      '\\nDecision Tree (min_samples_leaf = 5,max_depth = 8): ',tree3_mse\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting a limit on max_depth increases our error, but it can help ensure our model isn't overfitted. However, considering the MSE was almost doubled when imposing a limit on depth, we wont include this parameter in our model.\n",
    "\n",
    "It appears the decision tree regressor has much higher accuracy than linear regression.\n",
    "\n",
    "## Random Forest Algorithm\n",
    "\n",
    "Now that we have built a linear regression model and decision tree model, let's apply the random forest algorithm, which improves on the decision tree algorithm. \n",
    "\n",
    "Random forests tend to be much more accurate than simple models like linear regression, and tend to overfit much less than decision trees. Random forests can still be prone to overfitting however, so it is important to continue tuning parameters like minimum samples per leaf and maximum depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE:  17251.40179481665 \n",
      "Simple Decision Tree MSE:  3601.053006329114 \n",
      "Decision Tree (min_samp_leaf = 5) MSE:  2767.3647852621157 \n",
      "Simple Random Forest MSE:  1945.104269434855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "forest.fit(train[features],train['cnt'])\n",
    "forest_prediction = forest.predict(test[features])\n",
    "\n",
    "forest_mse = mean_squared_error(test['cnt'],forest_prediction)\n",
    "\n",
    "print(\"Linear Regression MSE: \",lr_mse,\n",
    "      '\\nSimple Decision Tree MSE: ',tree_mse,\n",
    "      '\\nDecision Tree (min_samp_leaf = 5) MSE: ',tree1_mse,\n",
    "      '\\nSimple Random Forest MSE: ',forest_mse\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Simple Random Forest has drastically approved our error value again, now below 2000. Let's experiment with various parameters of the RandomForestRegressor class to continue to minimize the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE:  17251.40179481665 \n",
      "Simple Decision Tree MSE:  3601.053006329114 \n",
      "Decision Tree (min_samples_leaf = 5) MSE:  2767.3647852621157 \n",
      "Simple Random Forest MSE:  1945.104269434855 \n",
      "Random Forest (min_samples_leaf = 3) MSE:  1953.6200300003507\n"
     ]
    }
   ],
   "source": [
    "forest1 = RandomForestRegressor(min_samples_leaf = 3)\n",
    "forest1.fit(train[features],train['cnt'])\n",
    "forest1_prediction = forest1.predict(test[features])\n",
    "\n",
    "forest1_mse = mean_squared_error(test['cnt'],forest1_prediction)\n",
    "\n",
    "print(\"Linear Regression MSE: \",lr_mse,\n",
    "      '\\nSimple Decision Tree MSE: ',tree_mse,\n",
    "      '\\nDecision Tree (min_samples_leaf = 5) MSE: ',tree1_mse,\n",
    "      '\\nSimple Random Forest MSE: ',forest_mse,\n",
    "      '\\nRandom Forest (min_samples_leaf = 3) MSE: ',forest1_mse\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE:  17251.40179481665 \n",
      "Simple Decision Tree MSE:  3601.053006329114 \n",
      "Decision Tree (min_samples_leaf = 5) MSE:  2767.3647852621157 \n",
      "Simple Random Forest MSE:  1945.104269434855 \n",
      "Random Forest (min_samples_leaf = 3) MSE:  1953.6200300003507 \n",
      "Random Forest (max_depth = 7) MSE:  6023.994074297851\n"
     ]
    }
   ],
   "source": [
    "forest2 = RandomForestRegressor(max_depth = 7)\n",
    "forest2.fit(train[features],train['cnt'])\n",
    "forest2_prediction = forest2.predict(test[features])\n",
    "\n",
    "forest2_mse = mean_squared_error(test['cnt'],forest2_prediction)\n",
    "\n",
    "print(\"Linear Regression MSE: \",lr_mse,\n",
    "      '\\nSimple Decision Tree MSE: ',tree_mse,\n",
    "      '\\nDecision Tree (min_samples_leaf = 5) MSE: ',tree1_mse,\n",
    "      '\\nSimple Random Forest MSE: ',forest_mse,\n",
    "      '\\nRandom Forest (min_samples_leaf = 3) MSE: ',forest1_mse,\n",
    "      '\\nRandom Forest (max_depth = 7) MSE: ',forest2_mse\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE:  17251.40179481665 \n",
      "Simple Decision Tree MSE:  3601.053006329114 \n",
      "Decision Tree (min_samples_leaf = 5) MSE:  2767.3647852621157 \n",
      "Simple Random Forest MSE:  1945.104269434855 \n",
      "Random Forest (min_samples_leaf = 3) MSE:  1953.6200300003507 \n",
      "Random Forest (max_depth = 7) MSE:  6023.994074297851 \n",
      "Random Forest (n_estimators = 50, min_samples_leaf = 3) MSE:  1833.329359076082\n"
     ]
    }
   ],
   "source": [
    "forest3 = RandomForestRegressor(n_estimators = 50,min_samples_leaf = 3)\n",
    "forest3.fit(train[features],train['cnt'])\n",
    "forest3_prediction = forest3.predict(test[features])\n",
    "\n",
    "forest3_mse = mean_squared_error(test['cnt'],forest3_prediction)\n",
    "\n",
    "print(\"Linear Regression MSE: \",lr_mse,\n",
    "      '\\nSimple Decision Tree MSE: ',tree_mse,\n",
    "      '\\nDecision Tree (min_samples_leaf = 5) MSE: ',tree1_mse,\n",
    "      '\\nSimple Random Forest MSE: ',forest_mse,\n",
    "      '\\nRandom Forest (min_samples_leaf = 3) MSE: ',forest1_mse,\n",
    "      '\\nRandom Forest (max_depth = 7) MSE: ',forest2_mse,\n",
    "      '\\nRandom Forest (n_estimators = 50, min_samples_leaf = 3) MSE: ', forest3_mse\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the decision tree, the random forest was further improved by changing the min_samples_leaf parameter. This time, a value of 3 produced the best results. Max Depth again significantly worsened our error, so we will not use this parameter going forward.\n",
    "\n",
    "We also explored the n_estimators parameter, which determines how many trees we have in our forest. This parameter did reduce the error, but at the cost of compute time. It did not create a significant enough of an impact on our error to have 50 trees in our forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps\n",
    "\n",
    "In this project we applied several machine learning models on the D.C. bike rentals dataset to predict how many bikes are rented each hour. \n",
    "\n",
    "First we explored a simple model, linear regression. This model performed the worst, likely because it underfit the data. \n",
    "\n",
    "We then turned to a decision tree model, which significantly reduced the error in our model. We found it was important to limit the complexity of the model to prevent overfitting.\n",
    "\n",
    "Finally, we explored a random forest model, which is typically more accurate than linear regression models and tend to overfit less compared to decision trees. We found this model produced the lowest error.\n",
    "\n",
    "To further improve our model, we can continue practice feature engineering to create new columns in our dataset. For example, we can create an index combining temperature, humidity, and wind speed to further describe the type of day it was. We can also try predicting casual and registered instead of cnt.\n",
    "\n",
    "### Creating a Heat Index Column\n",
    "\n",
    "Conceptually, hotter temperatures, higher winds, and higher humidity all create a less pleasant riding experience. Considering their significance moves in similar directions (riding conditions get worse the higher any of these get) and they are all normalized, we can likely sum them all together to get a general weather index. Let's try applying this to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE:  17251.40179481665 \n",
      "Simple Decision Tree MSE:  3601.053006329114 \n",
      "Decision Tree (min_samples_leaf = 5) MSE:  2767.3647852621157 \n",
      "Simple Random Forest MSE:  1945.104269434855 \n",
      "Random Forest THW Index(min_samples_leaf = 3) MSE:  1970.5022319799302\n"
     ]
    }
   ],
   "source": [
    "bike_rentals['thw_index'] = bike_rentals['atemp'] + bike_rentals['hum'] + bike_rentals['windspeed']\n",
    "\n",
    "train = bike_rentals.sample(frac = .8)\n",
    "test = bike_rentals.loc[~bike_rentals.index.isin(train.index)]\n",
    "\n",
    "features = features = ['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday',\n",
    "            'workingday', 'weathersit','temp','atemp','hum','windspeed', 'thw_index',\n",
    "            'time_label']\n",
    "\n",
    "forest_thw = RandomForestRegressor(min_samples_leaf = 3)\n",
    "forest_thw.fit(train[features],train['cnt'])\n",
    "forest_thw_prediction = forest_thw.predict(test[features])\n",
    "\n",
    "forest_thw_mse = mean_squared_error(test['cnt'],forest_thw_prediction)\n",
    "\n",
    "print(\"Linear Regression MSE: \",lr_mse,\n",
    "      '\\nSimple Decision Tree MSE: ',tree_mse,\n",
    "      '\\nDecision Tree (min_samples_leaf = 5) MSE: ',tree1_mse,\n",
    "      '\\nSimple Random Forest MSE: ',forest_mse,\n",
    "      '\\nRandom Forest THW Index(min_samples_leaf = 3) MSE: ',forest_thw_mse\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding this feature did not improve our error. We could likely create a THW index if we did not have normalized values to apply a Heat Index + Wind Index formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simple Random Forest MSE:  1945.104269434855 \n",
      "Random Forest Casual(min_samples_leaf = 3) MSE:  234.6740007766716 \n",
      "Random Forest Registered(min_samples_leaf = 3) MSE:  1295.5086525294046\n"
     ]
    }
   ],
   "source": [
    "features = features = ['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday',\n",
    "            'workingday', 'weathersit','temp','atemp','hum','windspeed',\n",
    "            'time_label']\n",
    "\n",
    "forest_cas = RandomForestRegressor(min_samples_leaf = 3)\n",
    "forest_cas.fit(train[features],train['casual'])\n",
    "forest_cas_prediction = forest_cas.predict(test[features])\n",
    "\n",
    "forest_cas_mse = mean_squared_error(test['casual'],forest_cas_prediction)\n",
    "\n",
    "forest_reg = RandomForestRegressor(min_samples_leaf = 3)\n",
    "forest_reg.fit(train[features],train['registered'])\n",
    "forest_reg_prediction = forest_reg.predict(test[features])\n",
    "\n",
    "forest_reg_mse = mean_squared_error(test['registered'],forest_reg_prediction)\n",
    "\n",
    "print('\\nSimple Random Forest MSE: ',forest_mse,\n",
    "      '\\nRandom Forest Casual(min_samples_leaf = 3) MSE: ',forest_cas_mse,\n",
    "      '\\nRandom Forest Registered(min_samples_leaf = 3) MSE: ', forest_reg_mse\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Random Forest model calculated the number of casual riders and registered riders with much lower error than it predicted total riders! The most accurate model would calculate casual and registered riders separately, and then simply sum these values.\n",
    "\n",
    "The reason this likely occured is because casual and registered riders behave differently. Registered riders may ride bikes to and from work or to get from place to place for routine tasks in their lives, making it easier to predict their actions during certain hours.\n",
    "\n",
    "Similarly, casual riders likely are more often to leisurely use these bicycles in their freetime. It is likely that casual riders use bikes more on weekends and in evenings. \n",
    "\n",
    "By segmenting these two groups with different behaviors, we can improve our model significantly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
